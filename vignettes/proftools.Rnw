%%\VignetteEngine{knitr::knitr}
%%\VignetteIndexEntry{Using proftools}
\documentclass[nojss]{jss}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Luke Tierney\\University of Iowa \And 
        Riad Jarjour\\University of Iowa}
\title{Examining \proglang{R} Profiling Data: The \pkg{proftools} Package}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Luke Tierney, Riad Jarjour} %% comma-separated
\Plaintitle{Examining R Profiling Data:
  The proftools Package} %% without formatting
%$ \Shorttitle{\pkg{foo}: A Capitalized Title} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
  This note introduces the \pkg{proftools} package for
  examining data collected by \proglang{R}'s sampling profiler.
  \pkg{proftools} includes facilities for summarizing results at the
  function, call, and source line level; for filtering to narrow the
  focus to functions of primary interest; and for visualizing
  profiling data. Use of the package is illustrated with a small
  running example.
}
\Keywords{\pkg{proftools}, profiling, \proglang{R}, \code{Rprof}}
\Plainkeywords{proftools, profiling, R, Rprof} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Luke Tierney\\
  Department of Statistics and Actuarial Science\\
  Faculty of Statistics\\
  University of Iowa\\
  Iowa City, USA\\
  E-mail: \email{luke-tierney@uiowa.edu}\\
  URL: \url{http://homepage.stat.uiowa.edu/~luke/}
  
  Riad Jarjour\\
  Department of Statistics and Actuarial Science\\
  Faculty of Statistics\\
  University of Iowa\\
  Iowa City, USA\\
  E-mail: \email{riad-jarjour@uiowa.edu}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and <<>>=} commands.

\section{Introduction}
<<echo=FALSE,results='hide'>>=
library("proftools")
options(keep.source = TRUE)
knitr::opts_chunk$set(size = "small")
@ %%
Profiling is a program analysis method for determining where a program
run spends most of its execution time, and can be very helpful in
guiding programmer effort for improving program performance.
\proglang{R} includes a sampling based profiling mechanism that
records information about calls on the stack at specified time
intervals.  If available, information about the specific source code
lines active at the sampling point is recorded as well. Information
about time spent in the garbage collector can also be collected. The
collected profiling data is written to a file, by default the file
\code{Rprof.out} in the current working directory.  The function
\code{summaryRprof}, available in the \pkg{base} package in
\proglang{R}, provides a simple interface for examining this data. The
\href{https://github.com/ltierney/Rpkg-proftools}{\pkg{proftools}}
package provides a much more extensive set of tools for summarizing,
visualizing, and filtering this data.

\section{Collecting Profile Data}
The \pkg{proftools} package includes an example script \code{bootlm.R}
in the \code{samples} directory that runs several examples from the
\pkg{boot} package \citep{CantyRipley:Boot} and fits a simple linear
model. The file path can be obtained as
<<>>=
srcfile <- system.file("samples", "bootlmEx.R", package = "proftools")
@  %%

The traditional way to collect profiling data in R is to call
\code{Rprof} to start profiling, run the code to be profiled, and then
call \code{Rprof} again to end profiling. For example, to profile the
code in \code{bootlm.R}, and collect both source line and GC
information, you could use
<<eval = FALSE>>=
profout <- tempfile()
Rprof(file = profout, gc.profiling = TRUE, line.profiling = TRUE)
source(srcfile)
Rprof(NULL)
pd <- readProfileData(profout)
unlink(profout)
@ %%
The \pkg{proftools} package provides the alternative
<<cache = TRUE>>=
pd <- profileExpr(source(srcfile))
@ %%
By default \code{profileExpr} enables GC and source information to be
collected. It also trims off stack information leading up to the
\code{profileExpr} call.

\section{Summary Functions}
The most basic summary function is \code{funSummary} for summarizing
profile results at the function level. It produces information similar
to the result returned by R's \code{summaryRprof} but in a more usable
form:
<<>>=
head(funSummary(pd), 10)
@ %%
The result returned by \code{funSummary}, and most summary functions,
is a data frame, so \code{head} can be used to focue on the top
entries. 

By default, when source information is available results are
summarized at the call level, so multiple calls to \code{boot} from
different source lines are shown separately. This can be suppressed by
supplying the \code{srclines = FALSE} argument:
<<>>=
head(funSummary(pd, srclines = FALSE), 10)
@ %%

Data can also be summarized by call:
<<>>=
head(callSummary(pd), 10)
@ %%

When source information is available in the profile data the
\code{srcSummary} function can be used to summarize at the source line
level; only lines appearing in the sample are included:
<<>>=
srcSummary(pd)
@ %%
The function \code{annotateSource} can show the full files with
profiling annotations.

A useful way to examine profile data is to look for hot execution
paths.  This approach sorts functions called at top level, i.e. at the
bottom of the call stack, by the total amount of time spent in their
top level calls; within each top level call to a function \code{f} the
functions called by \code{f} are sorted by the amount of time spent in
them within the top level call to \code{f}; and the process continues
for higher level calls. The function \code{hotPaths} produces a hot
path summary; the \code{total.pct} argument causes leaf functions in
stack traces to be pruned back until the execution time percentage for
each stack trace is at least \code{total.pct}:
<<>>=
hotPaths(pd, total.pct = 10.0)
@ %%
Examining the result of \code{hotPaths} starting with high values of
\code{total.pct} and then moving to lower values is a useful way to
expore where the computational effort is concentrated.  An alternative
to limiting the depth to which stack traces are followed is provided
by the \code{maxdepth} argument.
%% Other summary: \code{pathSummary}

\section{Filtering Profile Data}
The hot path summary shows information associated with the source
command itself that is not directly relevant to our analysis. The
\code{filterProfileData} function can be uses to select or omit
certain functions, drop functions with small self or total times,
narrow to a particular time interval, among others.  For example, by
selecting only stack traces that include calls to \code{withVisible}
and then trimming off the leading four calls we can focus just on the
work done in the sourced file:
<<>>=
filteredPD <- filterProfileData(pd, select = "withVisible", skip = 4)
@ %%
The hot path summary for this reduced profile is
<<>>=
hotPaths(filteredPD, total.pct = 10.0) 
@ %%

We can use the \code{focus} filter to further narrow our examination
to stack frames containing calls to \code{glm} and also remove all
calls preceding the first \code{glm} call from the selected stack
frames. For this reduced data it also makes sense to follow the paths
further by lowering \code{total.pct} to 5\%:
<<>>=
glmPD <- filterProfileData(filteredPD, focus = "glm")
hotPaths(glmPD, total.pct = 5.0)
@ %%


\section{Visualizing Profile Data}
Call graphs annotated with profile information are a very popular way
to view profiling results.  \code{plotProfileCallGraph} uses the
\pkg{graph} \citep{Gentleman:graph} and \pkg{Rgraphviz}
\cite{Gentry:Rgraphviz} packages from Bioconductor to render an
annotated call graph. The default style for the graph is based on the
style used in \href{https://github.com/gperftools}{Google's profiling
  library} but can be customized in a number of ways.  A call graph
for the full profile data is produced by
<<fullCallGraphCmd, eval = FALSE>>=
plotProfileCallGraph(pd)
@ 
and is shown in Figure \ref{fullCallGraphFig}.
\begin{figure}
  \centering
<<echo=FALSE>>=
<<fullCallGraphCmd>>
@ %%
\caption{Full call graph of \code{pd}.}
\label{fullCallGraphFig}
\end{figure}

We can obtain a more readable graph by fitering. For example, to
examine the \code{glm.fit} call and its callees we can use
<<filteredCallGraphCmd, eval = FALSE>>=
plotProfileCallGraph(filterProfileData(pd, focus = "glm.fit"))
@ 
\begin{figure}
  \centering
<<echo=FALSE>>=
<<filteredCallGraphCmd>>
@ %%
\caption{Call graph for \code{glm.fit} call.}
\label{filteredCallGraphFig}
\end{figure}
The result is shown in Figure \ref{filteredCallGraphFig}.

A printed version of the call graph, similar to the call graph
produced by \code{gprof} \citep{Graham:1982:GCG:800230.806987}, can be
obtained with \code{printProfileCallGraph}.  For the subgraph of the
\code{glm.fit} calls, for example,
<<printProfileCallGraph, eval=FALSE>>=
printProfileCallGraph(filterProfileData(pd, focus = "glm.fit"))
@ %%
produces the printed representation shown in Figure \ref{printGraphFig}.
\begin{figure}
  \tiny
<<echo = FALSE, comment = NA>>=
<<printProfileCallGraph>>
@ %%
\caption{Printed call graph.}
\label{printGraphFig}
\end{figure}

Another visualization sometimes used is a
\href{http://www.brendangregg.com/flamegraphs.html}{flame graph}.  By
default the \code{flameGraph} function orders functions within call
levels by execution time, which produces a visual representation of
the hot path summary;
<<flameGraphCmd, eval = FALSE>>=
flameGraph(pd)
@ %%
\begin{figure}
  \centering
<<echo = FALSE, out.width = "4in">>=
<<flameGraphCmd>>
@ %%
\caption{Flame graph visualizing hot paths for the full profile data.}
\label{flameGraphFig}
\end{figure}
the result is shown in Figure \ref{flameGraphFig}.  A flame graph of
the filtered data is produced by
<<filteredFlameGraphCmd, eval = FALSE>>=
flameGraph(filteredPD)
@ %%
\begin{figure}
  \centering
<<echo=FALSE, out.width = "4in">>=
<<filteredFlameGraphCmd>>
@ %%
\caption{Flame graph of the filtered profile data.}
\label{filteredFlameGraphFig}
\end{figure}
and shown in Figure \ref{filteredFlameGraphFig}
%% Furthermore, an svg file of the graph can be outputted by using the
%% svg argument:
%% <<eval=FALSE>>=
%% flameGraph(pd, svg = "graph.svg", order = "hot")
%% @ 

Specifying \code{order = "time"} shows the calls in the order in which
they occurred:
<<timeGraphCmd, eval = FALSE>>=
flameGraph(pd, order = "time")
@ %%
\begin{figure}
  \centering
<<echo=FALSE, out.width = "4in">>=
<<timeGraphCmd>>
@ %%
\caption{Time graph of the full profile data.}
\label{timeGraphFig}
\end{figure}
Figure \ref{timeGraphFig} shows the \code{boot} calls preceding the
data generation for the \code{lm} call and the \code{lm} call itself.

Flame graphs can also order functions within a level alphabetically.

A third visualization that is sometimes used is a callee tree map,
produced by
<<calleeTreeCmd, eval = FALSE>>=
calleeTreeMap(pd)
@ %%
\begin{figure}
  \centering
<<echo=FALSE, out.width = "4in">>=
<<calleeTreeCmd>>
@ %%
\caption{Call tree map of the full profile data.}
\label{calleeTreeMapFig}
\end{figure}
and shown in Figure \ref{calleeTreeMapFig}.

\section{Graphical User Interfaces}
The function \code{writeCallgrindFile} can be used to write the
profile data in \href{valgrind.org}{Valgrind's} \code{callgrind}
format for use with the
\href{http://kcachegrind.sourceforge.net/html/Home.html}{\code{kcachegrind}}
or \code{qcachegrind} graphical user interfaces available on Linux and
Mac OS X.

Graphical user interfaces within R will be made available in the
\href{https://github.com/ltierney/Rpkg-proftools-GUI}{\pkg{proftoolsGUI}}
package. The current development version provides two interfaces, one
based on \pkg{gWidgets2} \citep{Verzani:gWidgets2} and one on
\pkg{shiny} \citep{Chang:shiny}.

\section{Fixups}
The time trimming isn't right. It's good in \code{hotPaths} but not in
\code{filterProfileData}. This function does more or less what
\code{hotPaths} trimming does for \code{total.pct = 100 p} but not as
efficiently.
<<>>=
foo <- function(pd, p){
    trim <- function(x) {
        n <- length(x)
        if (n > 0) x[-n] else x
    }
    repeat {
        lns <- sapply(pd$stacks, length)
        low <- pd$counts < p * pd$total
        if (sum(low) == 0 || max(lns[low]) <=1)
            return(pd)
        to <- ifelse(low & lns == max(lns[low]), lns - 1, lns)
        pd <- proftools:::prunePD(pd, to = to)
    }
}
@ %%
This does a nice job; should do about what hot paths trimming on total does.
<<fig.cap="Better filtered view">>=
plotProfileCallGraph(foo(pd, .05))
@ %%

The \code{focudPD} code seesm more reasonable than this.
This should be closer to removing low total nodes:
<<>>=
bar <- function(pd, p) {
    fs <- funSummary(pd, srclines=FALSE)
    funs <- rownames(fs)
    low <- funs[fs$total.pct < p * 100]
    to <- sapply(pd$stacks, function(x) min(match(low,x, length(x) + 1)))
    ## what if to[i] == 0?
    proftools:::prunePD(pd, to = pmax(1, to - 1))
}
@ %%
Need to figure out what \verb|??| means in
\code{hotPaths(bar(pd, 0.1))}
and compare to
\code{hotPaths(pd, total.pct=10)}

Callgrind for sourced code is more useful if we trim off the source
stuff and add a fake function called something like \code{<TOP>}; this
way \code{kcachegrind} will whoud the annotated source file for the
fake function. This code does the trick; it would need adjusting if
the implementation of \code{source} changes:
<<>>=
if (all(sapply(pd$stacks, `[`, 1) == "source") &&
    all(sapply(pd$stacks, `[`, 2) == "withVisible") &&
    all(sapply(pd$stacks, `[`, 3) == "eval") &&
    all(sapply(pd$stacks, `[`, 4) == "eval")) {
    pd <- filterProfileData(pd, skip = 4)
    pd$refs <- lapply(pd$refs, function(x) c("1#1", x))
    pd$stacks <- lapply(pd$stacks, function(x) c("<TOP>", x))
}
@ 

\bibliography{proftools}
\end{document}
